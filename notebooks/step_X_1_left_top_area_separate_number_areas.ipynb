{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import tensorflow.contrib.slim as slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../')\n",
    "sys.path.append('../datasets/')\n",
    "sys.path.append('../nets/')\n",
    "sys.path.append('../preprocessing/')\n",
    "\n",
    "import synthtext\n",
    "synthtext_dataset = synthtext.get_split('test', '/home/mobile/data/synthtext/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ssd_vgg_512, ssd_common, np_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ssd_vgg_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TensorFlow session: grow memory when needed. TF, DO NOT USE ALL MY GPU MEMORY!!!\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "config = tf.ConfigProto(log_device_placement=False, gpu_options=gpu_options)\n",
    "isess = tf.InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net_shape = (512, 512)\n",
    "data_format = 'NHWC'\n",
    "img_input = tf.placeholder(tf.uint8, shape=(None, None, 3))\n",
    "# Evaluation pre-processing: resize to SSD net shape.\n",
    "image_pre, labels_pre, bboxes_pre, bbox_img = ssd_vgg_preprocessing.preprocess_for_eval(\n",
    "    img_input, None, None, net_shape, data_format, resize=ssd_vgg_preprocessing.Resize.WARP_RESIZE)\n",
    "image_4d = tf.expand_dims(image_pre, 0)\n",
    "\n",
    "# Define the SSD model.\n",
    "ssd_params = ssd_vgg_512.SSDNet.default_params._replace(num_classes=2)\n",
    "ssd_net = ssd_vgg_512.SSDNet(ssd_params)\n",
    "with slim.arg_scope(ssd_net.arg_scope(data_format=data_format)):\n",
    "    predictions, localisations, _, _ = ssd_net.net(image_4d, is_training=False, reuse=None)\n",
    "\n",
    "\n",
    "# Restore SSD model.\n",
    "ckpt_filename = '../checkpoints/model.ckpt-104129'\n",
    "isess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(isess, ckpt_filename)\n",
    "\n",
    "# SSD default anchor boxes.\n",
    "ssd_anchors = ssd_net.anchors(net_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_image(img, select_threshold=0.5, nms_threshold=.45, net_shape=(512, 512)):\n",
    "    # Run SSD network.\n",
    "    rimg, rpredictions, rlocalisations, rbbox_img = isess.run([image_4d, predictions, localisations, bbox_img],\n",
    "                                                              feed_dict={img_input: img})\n",
    "    \n",
    "    # Get classes and bboxes from the net outputs.\n",
    "    rclasses, rscores, rbboxes = np_methods.ssd_bboxes_select(\n",
    "            rpredictions, rlocalisations, ssd_anchors,\n",
    "            select_threshold=select_threshold, img_shape=net_shape, num_classes=1, decode=True)\n",
    "    \n",
    "    rbboxes = np_methods.bboxes_clip(rbbox_img, rbboxes)\n",
    "    rclasses, rscores, rbboxes = np_methods.bboxes_sort(rclasses, rscores, rbboxes, top_k=400)\n",
    "    rclasses, rscores, rbboxes = np_methods.bboxes_nms(rclasses, rscores, rbboxes, nms_threshold=nms_threshold)\n",
    "    # Resize bboxes to original image shape. Note: useless for Resize.WARP!\n",
    "    rbboxes = np_methods.bboxes_resize(rbbox_img, rbboxes)\n",
    "    return rclasses, rscores, rbboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def collision_of_box(box1, box2):\n",
    "    x11, y11, x12, y12 = box1\n",
    "    x21, y21, x22, y22 = box2\n",
    "    \n",
    "    width1 = x12 - x11\n",
    "    height1 = y12 - y11\n",
    "    \n",
    "    width2 = x22 - x21\n",
    "    height2 = y22 - y21\n",
    "    \n",
    "    union = min(x11, x21), min(y11, y21), max(x12, x22), max(y12, y22)\n",
    "    \n",
    "    \n",
    "    union_width = union[2] - union[0]\n",
    "    union_height = union[3] - union[1]\n",
    "    \n",
    "    return union_width < (width2 + width1) and union_height < (height1 + height2)\n",
    "\n",
    "def group_box_by_collision(boxes, fn_collison):\n",
    "    groups = []\n",
    "\n",
    "    for idx, box in enumerate(boxes):\n",
    "        b_collision = False\n",
    "\n",
    "        insect_g = []\n",
    "        for id_g, group in enumerate(groups):\n",
    "            for i in group:\n",
    "                if(fn_collison(boxes[i], box)):\n",
    "                    group.append(idx)\n",
    "                    insect_g.append(id_g)\n",
    "                    b_collision = True\n",
    "                    break\n",
    "        remain = [i for i in range(len(groups)) if i not in insect_g]\n",
    "\n",
    "        if len(insect_g) > 0:\n",
    "            merges = []\n",
    "            for g in insect_g:\n",
    "                merges += groups[g]\n",
    "            merges = list(set(merges))\n",
    "            new_groups = [merges]\n",
    "            for r in remain:\n",
    "                new_groups.append(groups[r])\n",
    "\n",
    "            groups = new_groups\n",
    "\n",
    "        if not b_collision:\n",
    "            groups.append([idx])\n",
    "    \n",
    "    return groups\n",
    "\n",
    "class CollisionLineMajor(object):\n",
    "    def __init__(self, line_threshold=1.0):\n",
    "        self.line_threshold = line_threshold\n",
    "        \n",
    "    def __call__(self, box1, box2):\n",
    "        x11, y11, x12, y12 = box1\n",
    "        x21, y21, x22, y22 = box2\n",
    "\n",
    "        height1 = x12 - x11\n",
    "        width1 = y12 - y11\n",
    "\n",
    "        height2 = x22 - x21\n",
    "        width2 = y22 - y21\n",
    "\n",
    "        union = min(x11, x21), min(y11, y21), max(x12, x22), max(y12, y22)\n",
    "        insec = max(x11, x21), max(y11, y21), min(x12, x22), min(y12, y22)\n",
    "\n",
    "        union_height = union[2] - union[0]\n",
    "        union_width = union[3] - union[1]\n",
    "\n",
    "        insec_height = insec[2] - insec[0] # x\n",
    "\n",
    "        # split the 密码区和关键信息区\n",
    "        return float(union_height) / (height2 + height1) < self.line_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from invorec import common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def y_of_groups(boxes, groups):\n",
    "    return [np.min(boxes[g], axis=0)[0] for g in groups]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dir_name = \"../../orientation_detection/data/output/vivo/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "counter = 1\n",
    "for filename in os.listdir(dir_name)[0:]:\n",
    "    if os.path.splitext(filename)[1].lower() not in ['.jpg', '.jpeg']:\n",
    "        print(filename)\n",
    "        print(os.path.splitext(filename)[1].lower())\n",
    "        continue\n",
    "    print(counter)\n",
    "    counter +=1\n",
    "    path = os.path.join(dir_name, filename)\n",
    "    cvim = cv2.imread(path)\n",
    "    cvim = cv2.cvtColor(cvim, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    width = 900\n",
    "    ratio = float(width) / cvim.shape[1]\n",
    "    img = cv2.resize(cvim, (width, int(cvim.shape[0]*ratio)))\n",
    "    clip_width = 900\n",
    "    clip_img = common.clip_rect(img, (width - clip_width, 0, clip_width, 300))\n",
    "    \n",
    "    \n",
    "    rclasses, rscores, rbboxes =  process_image(clip_img)\n",
    "\n",
    "    threshold = 0.91\n",
    "    sel = rscores > threshold\n",
    "\n",
    "    boxes = rbboxes[sel]\n",
    "    classes = rclasses[sel]\n",
    "    scores = rscores[sel]\n",
    "\n",
    "    left_top_idx = (boxes[:, 0] < 0.5) & (boxes[:, 1] > 0.5)\n",
    "\n",
    "    left_top_classes = classes[left_top_idx]\n",
    "    left_top_scores = scores[left_top_idx]\n",
    "    left_top_boxes = boxes[left_top_idx]\n",
    "    \n",
    "    # sel the top group\n",
    "    number_area_splitor = CollisionLineMajor(1.3)\n",
    "    groups = group_box_by_collision(left_top_boxes, number_area_splitor)\n",
    "    \n",
    "    ys = y_of_groups(left_top_boxes, groups)\n",
    "    y_idxs = np.argsort(ys)\n",
    "    \n",
    "    \n",
    "    sel_group_id = y_idxs[0]\n",
    "    # remove noise group on the top\n",
    "    for _idx in y_idxs:\n",
    "        if len(groups[_idx]) > 3:\n",
    "            sel_group_id = _idx\n",
    "            break\n",
    "    \n",
    "    top_group_classes = left_top_classes[groups[sel_group_id]]\n",
    "    top_group_scores = left_top_scores[groups[sel_group_id]]\n",
    "    top_group_boxes = left_top_boxes[groups[sel_group_id]]\n",
    "    \n",
    "    # sep top group into lines\n",
    "    date_area_splitor = CollisionLineMajor(0.8)\n",
    "    groups = group_box_by_collision(top_group_boxes, date_area_splitor)\n",
    "    \n",
    "    for tag, group in enumerate(groups):\n",
    "        for idx in group:\n",
    "            top_group_classes[idx] = tag+1\n",
    "\n",
    "    visualization.plt_bboxes(clip_img, top_group_classes, \n",
    "                                       top_group_scores, \n",
    "                                       top_group_boxes, \n",
    "                                       figsize=(30,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
