{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    112  126  14   153  167  180  194\t27  40\t54  68\t81  95\r\n",
      "10   113  127  140  154  168  181  195\t28  41\t55  69\t82  96\r\n",
      "100  114  128  141  155  169  182  196\t29  42\t56  7\t83  97\r\n",
      "101  115  129  142  156  17   183  197\t3   43\t57  70\t84  98\r\n",
      "102  116  13   143  157  170  184  198\t30  44\t58  71\t85  99\r\n",
      "103  117  130  144  158  171  185  199\t31  45\t59  72\t86  gt.mat\r\n",
      "104  118  131  145  159  172  186  2\t32  46\t6   73\t87  image_shape.pkl\r\n",
      "105  119  132  146  16\t 173  187  20\t33  47\t60  74\t88\r\n",
      "106  12   133  147  160  174  188  200\t34  48\t61  75\t89\r\n",
      "107  120  134  148  161  175  189  21\t35  49\t62  76\t9\r\n",
      "108  121  135  149  162  176  19   22\t36  5\t63  77\t90\r\n",
      "109  122  136  15   163  177  190  23\t37  50\t64  78\t91\r\n",
      "11   123  137  150  164  178  191  24\t38  51\t65  79\t92\r\n",
      "110  124  138  151  165  179  192  25\t39  52\t66  8\t93\r\n",
      "111  125  139  152  166  18   193  26\t4   53\t67  80\t94\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/mobile/Downloads/SynthText/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read matlab mat format file\n",
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = '/home/mobile/Downloads/SynthText/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gt = sio.loadmat(data_dir + 'gt.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = gt['imnames'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(772875, 85875)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# constant needed in split_to_size\n",
    "int(num * 0.9), num - int(num * 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the name list of image\n",
    "idx_of_img = 4\n",
    "image_file = data_dir + str(gt['imnames'][:,idx_of_img][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im  = cv2.cvtColor(cv2.imread(image_file), cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list of words seems useless in this scenario\n",
    "for i, txt in enumerate(gt['txt'][:,idx_of_img][0]):\n",
    "    print(\"{i}th word is {word}\".format(i=i, word=txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# recaculate bbox of words\n",
    "wordBB = gt['wordBB'][:,idx_of_img][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert wordBB to aabb boxes list\n",
    "def convert_rotbbox_to_aabb(wordBB, image_size):\n",
    "    word_len = wordBB.shape[2]\n",
    "    height, width = image_size\n",
    "    aabb = np.zeros((word_len, 4), dtype=np.float32)\n",
    "    for i in xrange(word_len):\n",
    "        x_min = np.min(wordBB[0, :, i]) / float(width)\n",
    "        x_max = np.max(wordBB[0, :, i]) / float(width)\n",
    "        y_min = np.min(wordBB[1, : ,i]) / float(height)\n",
    "        y_max = np.max(wordBB[1, : ,i]) / float(height)\n",
    "        aabb[i,:] = np.array([y_min, x_min, y_max, x_max])\n",
    "        \n",
    "    return aabb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aabb = convert_rotbbox_to_aabb(wordBB, im.shape[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for bbox in aabb:\n",
    "    y_min, x_min, y_max, x_max = bbox\n",
    "    cv2.rectangle(im, \n",
    "                  (int(x_min*im.shape[1]), int(y_min*im.shape[0])), \n",
    "                  (int(x_max*im.shape[1]), int(y_max*im.shape[0])), \n",
    "                  (255, 0, 0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# should read all image's size into a single file\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('image_size.pkl', 'w') as f:\n",
    "    dst = {}\n",
    "    num_of_file = gt['imnames'].shape[1]\n",
    "    for idx_of_img in tqdm(xrange(num_of_file)):\n",
    "        image_file_name = str(gt['imnames'][:,idx_of_img][0][0])\n",
    "        path = data_dir + image_file_name\n",
    "        height, width, depth = cv2.imread(path).shape\n",
    "        dst[image_file_name] = [height, width, depth]\n",
    "    \n",
    "    pickle.dump(dst, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# to tf-record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VOC_LABELS = {\n",
    "    'none': (0, 'Background'),\n",
    "    'text': (1, 'text')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('image_shape.pkl') as f:\n",
    "    dst = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path.append('../datasets/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dataset_utils import int64_feature, float_feature, bytes_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SAMPLES_PER_FILES = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert wordBB to aabb boxes list\n",
    "def convert_rotbbox_to_aabb(wordBB, image_size):\n",
    "    if len(wordBB.shape) < 3:\n",
    "        wordBB = np.expand_dims(wordBB, axis=-1)\n",
    "\n",
    "    word_len = wordBB.shape[2]\n",
    "    height, width = image_size\n",
    "    aabb = np.zeros((word_len, 4), dtype=np.float32)\n",
    "    for i in xrange(word_len):\n",
    "        x_min = np.min(wordBB[0, :, i]) / float(width)\n",
    "        x_max = np.max(wordBB[0, :, i]) / float(width)\n",
    "        y_min = np.min(wordBB[1, : ,i]) / float(height)\n",
    "        y_max = np.max(wordBB[1, : ,i]) / float(height)\n",
    "        aabb[i,:] = np.array([y_min, x_min, y_max, x_max])\n",
    "\n",
    "    return aabb\n",
    "\n",
    "def run(dataset_dir, output_dir, split_ratio=0.9, shuffling=False):\n",
    "    \"\"\"Runs the conversion operation.\n",
    "\n",
    "    Args:\n",
    "      dataset_dir: The dataset directory where the dataset is stored.\n",
    "      output_dir: Output directory.\n",
    "    \"\"\"\n",
    "    \n",
    "    def _process_image(directory, idx_of_img):\n",
    "        \"\"\"Process a image and annotation file.\n",
    "\n",
    "        Args:\n",
    "          directory: the syntext data directory\n",
    "          idx_of_img: int, the index of images in gt.mat\n",
    "        Returns:\n",
    "          image_data: string, JPEG encoding of RGB image.\n",
    "          shape: the image shape\n",
    "          bboxes: the bounding box of text\n",
    "          labels: the label of text always 1, there is only one label\n",
    "        \"\"\"\n",
    "        # Read the image file.\n",
    "        name = str(gt['imnames'][:,idx_of_img][0][0])\n",
    "        filename = directory + name\n",
    "        image_data = tf.gfile.FastGFile(filename, 'r').read()\n",
    "\n",
    "        shape = image_shapes[name]\n",
    "\n",
    "        wordBB = gt['wordBB'][:,idx_of_img][0]\n",
    "\n",
    "        bboxes = convert_rotbbox_to_aabb(wordBB, shape[:2])\n",
    "        labels = [VOC_LABELS['text'][0]] * len(bboxes)\n",
    "\n",
    "        return image_data, shape, bboxes, labels\n",
    "    \n",
    "    def _convert_to_example(image_data, shape, bboxes, labels):\n",
    "        \"\"\"Build an Example proto for an image example.\n",
    "\n",
    "        Args:\n",
    "          image_data: string, JPEG encoding of RGB image; Sythtext images are always .jpg\n",
    "          labels: list of integers, identifier for the ground truth;\n",
    "          bboxes: list of bounding boxes; each box is a list of integers;\n",
    "              specifying [xmin, ymin, xmax, ymax]. All boxes are assumed to belong\n",
    "              to the same label as the image label.\n",
    "          shape: 3 integers, image shapes in pixels.\n",
    "        Returns:\n",
    "          Example proto\n",
    "        \"\"\"\n",
    "        xmin = []\n",
    "        ymin = []\n",
    "        xmax = []\n",
    "        ymax = []\n",
    "        for b in bboxes:\n",
    "            assert len(b) == 4\n",
    "            # pylint: disable=expression-not-assigned\n",
    "            [l.append(point) for l, point in zip([ymin, xmin, ymax, xmax], b)]\n",
    "            # pylint: enable=expression-not-assigned\n",
    "\n",
    "        image_format = b'JPEG'\n",
    "        example = tf.train.Example(features=tf.train.Features(feature={\n",
    "                'image/height': int64_feature(shape[0]),\n",
    "                'image/width': int64_feature(shape[1]),\n",
    "                'image/channels': int64_feature(shape[2]),\n",
    "                'image/shape': int64_feature(shape),\n",
    "                'image/object/bbox/xmin': float_feature(xmin),\n",
    "                'image/object/bbox/xmax': float_feature(xmax),\n",
    "                'image/object/bbox/ymin': float_feature(ymin),\n",
    "                'image/object/bbox/ymax': float_feature(ymax),\n",
    "                'image/object/bbox/label': int64_feature(labels),\n",
    "                'image/format': bytes_feature(image_format),\n",
    "                'image/encoded': bytes_feature(image_data)}))\n",
    "        return example\n",
    "    \n",
    "    def _add_to_tfrecord(dataset_dir, idx, tfrecord_writer):\n",
    "        \"\"\"Loads data from image and annotations files and add them to a TFRecord.\n",
    "\n",
    "        Args:\n",
    "          dataset_dir: Dataset directory;\n",
    "          name: Image name to add to the TFRecord;\n",
    "          tfrecord_writer: The TFRecord writer to use for writing.\n",
    "        \"\"\"\n",
    "        image_data, shape, bboxes, labels = \\\n",
    "            _process_image(dataset_dir, idx)\n",
    "        example = _convert_to_example(image_data, shape, bboxes, labels)\n",
    "        tfrecord_writer.write(example.SerializeToString())\n",
    "        \n",
    "    def _get_output_filename(output_dir, split_name, idx):\n",
    "        return '%s/syntext_%s_%04d.tfrecord' % (output_dir, split_name, idx)\n",
    "\n",
    "    if not tf.gfile.Exists(dataset_dir):\n",
    "        tf.gfile.MakeDirs(dataset_dir)\n",
    "\n",
    "    print('read gt.mat file...')\n",
    "    gt = sio.loadmat(data_dir + 'gt.mat')\n",
    "    \n",
    "    print('read image_shape.pkl file...')\n",
    "    with open('image_shape.pkl') as f:\n",
    "        image_shapes = pickle.load(f)\n",
    "    \n",
    "    num_of_image = gt['imnames'].shape[1]\n",
    "    \n",
    "    assert num_of_image == len(image_shapes)\n",
    "    \n",
    "    # assert split_ratio belong to (0, 1)\n",
    "    num_for_train = int(num_of_image * split_ratio)\n",
    "    \n",
    "    # shuffle the indices\n",
    "    fileidxs = range(0, num_of_image)\n",
    "    if shuffling:\n",
    "        random.seed(RANDOM_SEED)\n",
    "        random.shuffle(fileidxs)\n",
    "    \n",
    "    # pick up indices for train and test\n",
    "#     idxs_for_train = fileidxs[:num_for_train]\n",
    "#     idxs_for_test = fileidxs[num_for_train:]\n",
    "    idxs_for_train = fileidxs[:200]\n",
    "    idxs_for_test = fileidxs[200:500]\n",
    "\n",
    "    # Process dataset files for trains\n",
    "    logging.info('convert data for train.')\n",
    "\n",
    "    fidx = 0\n",
    "    for idx in tqdm(idxs_for_train):\n",
    "        if idx % SAMPLES_PER_FILES == 0:\n",
    "            # Open new TFRecord file.\n",
    "            tf_filename = _get_output_filename(output_dir, 'train', fidx)\n",
    "            fidx += 1\n",
    "            \n",
    "        with tf.python_io.TFRecordWriter(tf_filename) as tfrecord_writer:\n",
    "            _add_to_tfrecord(dataset_dir, idx, tfrecord_writer)\n",
    "    \n",
    "    # Process dataset files for test\n",
    "    logging.info('convert data for test')\n",
    "\n",
    "    fidx = 0\n",
    "    for idx in tqdm(idxs_for_test):\n",
    "        if idx % SAMPLES_PER_FILES == 0:\n",
    "            # Open new TFRecord file.\n",
    "            tf_filename = _get_output_filename(output_dir, 'test', fidx)\n",
    "            fidx += 1\n",
    "            \n",
    "        with tf.python_io.TFRecordWriter(tf_filename) as tfrecord_writer:\n",
    "            _add_to_tfrecord(dataset_dir, idx, tfrecord_writer)\n",
    "    \n",
    "    print('\\nFinished converting the Syntext dataset!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run(data_dir, '/tmp/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
