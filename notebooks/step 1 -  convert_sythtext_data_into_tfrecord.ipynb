{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /home/mobile/Downloads/SynthText/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read matlab mat format file\n",
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = '/home/mobile/Downloads/SynthText/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gt = sio.loadmat(data_dir + 'gt.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num = gt['imnames'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constant needed in split_to_size\n",
    "int(num * 0.9), num - int(num * 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the name list of image\n",
    "idx_of_img = 4\n",
    "image_file = data_dir + str(gt['imnames'][:,idx_of_img][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im  = cv2.cvtColor(cv2.imread(image_file), cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of words seems useless in this scenario\n",
    "for i, txt in enumerate(gt['txt'][:,idx_of_img][0]):\n",
    "    print(\"{i}th word is {word}\".format(i=i, word=txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# recaculate bbox of words\n",
    "wordBB = gt['wordBB'][:,idx_of_img][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert wordBB to aabb boxes list\n",
    "def convert_rotbbox_to_aabb(wordBB, image_size):\n",
    "    word_len = wordBB.shape[2]\n",
    "    height, width = image_size\n",
    "    aabb = np.zeros((word_len, 4), dtype=np.float32)\n",
    "    for i in xrange(word_len):\n",
    "        x_min = np.min(wordBB[0, :, i]) / float(width)\n",
    "        x_max = np.max(wordBB[0, :, i]) / float(width)\n",
    "        y_min = np.min(wordBB[1, : ,i]) / float(height)\n",
    "        y_max = np.max(wordBB[1, : ,i]) / float(height)\n",
    "        aabb[i,:] = np.array([y_min, x_min, y_max, x_max])\n",
    "        \n",
    "    return aabb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aabb = convert_rotbbox_to_aabb(wordBB, im.shape[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for bbox in aabb:\n",
    "    y_min, x_min, y_max, x_max = bbox\n",
    "    cv2.rectangle(im, \n",
    "                  (int(x_min*im.shape[1]), int(y_min*im.shape[0])), \n",
    "                  (int(x_max*im.shape[1]), int(y_max*im.shape[0])), \n",
    "                  (255, 0, 0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# should read all image's size into a single file\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('image_size.pkl', 'w') as f:\n",
    "#     dst = {}\n",
    "#     num_of_file = gt['imnames'].shape[1]\n",
    "#     for idx_of_img in tqdm(xrange(num_of_file)):\n",
    "#         image_file_name = str(gt['imnames'][:,idx_of_img][0][0])\n",
    "#         path = data_dir + image_file_name\n",
    "#         height, width, depth = cv2.imread(path).shape\n",
    "#         dst[image_file_name] = [height, width, depth]\n",
    "    \n",
    "#     pickle.dump(dst, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# to tf-record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VOC_LABELS = {\n",
    "    'none': (0, 'Background'),\n",
    "    'text': (1, 'text')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../datasets/image_shape.pkl') as f:\n",
    "    dst = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path.append('../datasets/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dataset_utils import int64_feature, float_feature, bytes_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SAMPLES_PER_FILES = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert wordBB to aabb boxes list\n",
    "def convert_rotbbox_to_aabb(wordBB, image_size):\n",
    "    if len(wordBB.shape) < 3:\n",
    "        wordBB = np.expand_dims(wordBB, axis=-1)\n",
    "\n",
    "    word_len = wordBB.shape[2]\n",
    "    height, width = image_size\n",
    "    aabb = np.zeros((word_len, 4), dtype=np.float32)\n",
    "    for i in xrange(word_len):\n",
    "        x_min = np.min(wordBB[0, :, i]) / float(width)\n",
    "        x_max = np.max(wordBB[0, :, i]) / float(width)\n",
    "        y_min = np.min(wordBB[1, : ,i]) / float(height)\n",
    "        y_max = np.max(wordBB[1, : ,i]) / float(height)\n",
    "        aabb[i,:] = np.array([y_min, x_min, y_max, x_max])\n",
    "\n",
    "    return aabb\n",
    "\n",
    "def run(dataset_dir, output_dir, split_ratio=0.9, shuffling=False):\n",
    "    \"\"\"Runs the conversion operation.\n",
    "\n",
    "    Args:\n",
    "      dataset_dir: The dataset directory where the dataset is stored.\n",
    "      output_dir: Output directory.\n",
    "    \"\"\"\n",
    "    \n",
    "    def _process_image(directory, idx_of_img):\n",
    "        \"\"\"Process a image and annotation file.\n",
    "\n",
    "        Args:\n",
    "          directory: the syntext data directory\n",
    "          idx_of_img: int, the index of images in gt.mat\n",
    "        Returns:\n",
    "          image_data: string, JPEG encoding of RGB image.\n",
    "          shape: the image shape\n",
    "          bboxes: the bounding box of text\n",
    "          labels: the label of text always 1, there is only one label\n",
    "        \"\"\"\n",
    "        # Read the image file.\n",
    "        name = str(gt['imnames'][:,idx_of_img][0][0])\n",
    "        filename = directory + name\n",
    "        image_data = tf.gfile.FastGFile(filename, 'r').read()\n",
    "\n",
    "        shape = image_shapes[name]\n",
    "\n",
    "        wordBB = gt['wordBB'][:,idx_of_img][0]\n",
    "\n",
    "        bboxes = convert_rotbbox_to_aabb(wordBB, shape[:2])\n",
    "        labels = [VOC_LABELS['text'][0]] * len(bboxes)\n",
    "\n",
    "        return image_data, shape, bboxes, labels\n",
    "    \n",
    "    def _convert_to_example(image_data, shape, bboxes, labels):\n",
    "        \"\"\"Build an Example proto for an image example.\n",
    "\n",
    "        Args:\n",
    "          image_data: string, JPEG encoding of RGB image; Sythtext images are always .jpg\n",
    "          labels: list of integers, identifier for the ground truth;\n",
    "          bboxes: list of bounding boxes; each box is a list of integers;\n",
    "              specifying [xmin, ymin, xmax, ymax]. All boxes are assumed to belong\n",
    "              to the same label as the image label.\n",
    "          shape: 3 integers, image shapes in pixels.\n",
    "        Returns:\n",
    "          Example proto\n",
    "        \"\"\"\n",
    "        xmin = []\n",
    "        ymin = []\n",
    "        xmax = []\n",
    "        ymax = []\n",
    "        for b in bboxes:\n",
    "            assert len(b) == 4\n",
    "            # pylint: disable=expression-not-assigned\n",
    "            [l.append(point) for l, point in zip([ymin, xmin, ymax, xmax], b)]\n",
    "            # pylint: enable=expression-not-assigned\n",
    "\n",
    "        image_format = b'JPEG'\n",
    "        example = tf.train.Example(features=tf.train.Features(feature={\n",
    "                'image/height': int64_feature(shape[0]),\n",
    "                'image/width': int64_feature(shape[1]),\n",
    "                'image/channels': int64_feature(shape[2]),\n",
    "                'image/shape': int64_feature(shape),\n",
    "                'image/object/bbox/xmin': float_feature(xmin),\n",
    "                'image/object/bbox/xmax': float_feature(xmax),\n",
    "                'image/object/bbox/ymin': float_feature(ymin),\n",
    "                'image/object/bbox/ymax': float_feature(ymax),\n",
    "                'image/object/bbox/label': int64_feature(labels),\n",
    "                'image/format': bytes_feature(image_format),\n",
    "                'image/encoded': bytes_feature(image_data)}))\n",
    "        return example\n",
    "    \n",
    "    def _add_to_tfrecord(dataset_dir, idx, tfrecord_writer):\n",
    "        \"\"\"Loads data from image and annotations files and add them to a TFRecord.\n",
    "\n",
    "        Args:\n",
    "          dataset_dir: Dataset directory;\n",
    "          name: Image name to add to the TFRecord;\n",
    "          tfrecord_writer: The TFRecord writer to use for writing.\n",
    "        \"\"\"\n",
    "        image_data, shape, bboxes, labels = \\\n",
    "            _process_image(dataset_dir, idx)\n",
    "        example = _convert_to_example(image_data, shape, bboxes, labels)\n",
    "        tfrecord_writer.write(example.SerializeToString())\n",
    "        \n",
    "    def _get_output_filename(output_dir, split_name, idx):\n",
    "        return '%s/syntext_%s_%04d.tfrecord' % (output_dir, split_name, idx)\n",
    "\n",
    "    if not tf.gfile.Exists(dataset_dir):\n",
    "        tf.gfile.MakeDirs(dataset_dir)\n",
    "\n",
    "    print('read gt.mat file...')\n",
    "    gt = sio.loadmat(data_dir + 'gt.mat')\n",
    "    \n",
    "    print('read image_shape.pkl file...')\n",
    "    with open(data_dir + 'image_shape.pkl') as f:\n",
    "        image_shapes = pickle.load(f)\n",
    "    \n",
    "    num_of_image = gt['imnames'].shape[1]\n",
    "    \n",
    "    assert num_of_image == len(image_shapes)\n",
    "    \n",
    "    # assert split_ratio belong to (0, 1)\n",
    "    num_for_train = int(num_of_image * split_ratio)\n",
    "    \n",
    "    # shuffle the indices\n",
    "    fileidxs = range(0, num_of_image)\n",
    "    if shuffling:\n",
    "        random.seed(RANDOM_SEED)\n",
    "        random.shuffle(fileidxs)\n",
    "    \n",
    "    # pick up indices for train and test\n",
    "#     idxs_for_train = fileidxs[:num_for_train]\n",
    "#     idxs_for_test = fileidxs[num_for_train:]\n",
    "    idxs_for_train = fileidxs[:200]\n",
    "    idxs_for_test = fileidxs[200:500]\n",
    "\n",
    "    # Process dataset files for trains\n",
    "    logging.info('convert data for train.')\n",
    "\n",
    "    i, fidx = 0, 0\n",
    "    while i < len(idxs_for_train):\n",
    "        tf_filename = _get_output_filename(output_dir, 'train', fidx)\n",
    "        with tf.python_io.TFRecordWriter(tf_filename) as tfrecord_writer:\n",
    "            j = 0\n",
    "            while i < len(idxs_for_train) and j < SAMPLES_PER_FILES:\n",
    "                sys.stdout.write('\\r>> Converting image %d/%d' % (i+1, len(idxs_for_train)))\n",
    "                sys.stdout.flush()\n",
    "                _add_to_tfrecord(dataset_dir, idxs_for_train[i], tfrecord_writer)\n",
    "                i +=1\n",
    "                j +=1\n",
    "        \n",
    "        fidx += 1\n",
    "    \n",
    "    # Process dataset files for test\n",
    "    logging.info('convert data for test')\n",
    "\n",
    "    i, fidx = 0, 0\n",
    "    while i < len(idxs_for_test):\n",
    "        tf_filename = _get_output_filename(output_dir, 'test', fidx)\n",
    "        with tf.python_io.TFRecordWriter(tf_filename) as tfrecord_writer:\n",
    "            j = 0\n",
    "            while i < len(idxs_for_test) and j < SAMPLES_PER_FILES:\n",
    "                sys.stdout.write('\\r>> Converting image %d/%d' % (i+1, len(idxs_for_test)))\n",
    "                sys.stdout.flush()\n",
    "                _add_to_tfrecord(dataset_dir, idxs_for_test[i], tfrecord_writer)\n",
    "                i +=1\n",
    "                j +=1\n",
    "        \n",
    "        fidx += 1\n",
    "\n",
    "            \n",
    "    \n",
    "    print('\\nFinished converting the Syntext dataset!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read gt.mat file...\n",
      "read image_shape.pkl file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:convert data for train.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Converting image 200/200"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:convert data for test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Converting image 300/300\n",
      "Finished converting the Syntext dataset!\n"
     ]
    }
   ],
   "source": [
    "run(data_dir, '/tmp/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
