{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import tensorflow.contrib.slim as slim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## manually create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_pattern = 'syntext_%s_*.tfrecord'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "split_name = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_pattern = file_pattern % split_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# file_pattern has to have full path of data\n",
    "dataset_dir = '/home/mobile/data/synthtext/'\n",
    "file_pattern = os.path.join(dataset_dir, file_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reader = tf.TFRecordReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keys_to_features = {\n",
    "        'image/encoded': tf.FixedLenFeature((), tf.string, default_value=''),\n",
    "        'image/format': tf.FixedLenFeature((), tf.string, default_value='jpeg'),\n",
    "        'image/height': tf.FixedLenFeature([1], tf.int64),\n",
    "        'image/width': tf.FixedLenFeature([1], tf.int64),\n",
    "        'image/channels': tf.FixedLenFeature([1], tf.int64),\n",
    "        'image/shape': tf.FixedLenFeature([3], tf.int64),\n",
    "        'image/object/bbox/xmin': tf.VarLenFeature(dtype=tf.float32),\n",
    "        'image/object/bbox/ymin': tf.VarLenFeature(dtype=tf.float32),\n",
    "        'image/object/bbox/xmax': tf.VarLenFeature(dtype=tf.float32),\n",
    "        'image/object/bbox/ymax': tf.VarLenFeature(dtype=tf.float32),\n",
    "        'image/object/bbox/label': tf.VarLenFeature(dtype=tf.int64)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "items_to_handlers = {\n",
    "        'image': slim.tfexample_decoder.Image('image/encoded', 'image/format'),\n",
    "        'shape': slim.tfexample_decoder.Tensor('image/shape'),\n",
    "        'object/bbox': slim.tfexample_decoder.BoundingBox(\n",
    "                ['ymin', 'xmin', 'ymax', 'xmax'], 'image/object/bbox/'),\n",
    "        'object/label': slim.tfexample_decoder.Tensor('image/object/bbox/label')\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder = slim.tfexample_decoder.TFExampleDecoder(\n",
    "        keys_to_features, items_to_handlers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ITEMS_TO_DESCRIPTIONS = {\n",
    "    'image': 'A color image of varying height and width.',\n",
    "    'shape': 'Shape of the image',\n",
    "    'object/bbox': 'A list of bounding boxes, one per each object.',\n",
    "    'object/label': 'A list of labels, one per each object.',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "synthtext_dataset = slim.dataset.Dataset(\n",
    "            data_sources=file_pattern,\n",
    "            reader=reader,\n",
    "            decoder=decoder,\n",
    "            num_samples=200,\n",
    "            items_to_descriptions=ITEMS_TO_DESCRIPTIONS,\n",
    "            num_classes=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import from dataset module directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../datasets/')\n",
    "\n",
    "import synthtext\n",
    "\n",
    "synthtext_dataset = synthtext.get_split('train', '/home/mobile/data/synthtext/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## display some of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Graph().as_default():\n",
    "    data_provider = slim.dataset_data_provider.DatasetDataProvider(\n",
    "        synthtext_dataset, common_queue_capacity=32, common_queue_min=1)\n",
    "\n",
    "    image, bbox, label = data_provider.get(['image', 'object/bbox', 'object/label'])\n",
    "\n",
    "    with tf.Session() as sess:    \n",
    "        with slim.queues.QueueRunners(sess):\n",
    "            np_image, np_bboxes, np_label = sess.run([image, bbox, label])\n",
    "            height, width, _ = np_image.shape\n",
    "            for bbox in np_bboxes:\n",
    "                y_min, x_min, y_max, x_max = bbox\n",
    "                cv2.rectangle(np_image, \n",
    "                              (int(x_min*width), int(y_min*height)), \n",
    "                              (int(x_max*width), int(y_max*height)), \n",
    "                              (255, 0, 0), 2)\n",
    "            plt.figure()\n",
    "            plt.imshow(np_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
